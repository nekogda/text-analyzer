# TextAnalyzer

Приложение для вычисления частоты встречи символов по заданной строке (тестовое задание).

### Build instructions

```shell

$ git clone https://github.com/nekogda/text-analyzer.git
$ cd text-analyzer
$ ./mvnw test spring-boot:run

```

### Description

После запуска приложения, документация по rest-api будет доступна
в [swagger](http://localhost:8080/swagger-ui/index.html)

В задании не выдвигалось конкретных требований по характеристикам входных данных (ограничения по длинне и форматам
принимаемых от пользователя запросов). По этой причине решение строилось на предположении, что пользователь будет
присылать небольшие фрагменты текста в utf-8, и довольно редко. Другие кодировки использоваться не будут (
UTF-32BE,UTF-16BE,UTF-32LE,UTF-16LE).

Лимит по размеру текста выбран произвольно и состовляет 1000 символов, если пользовательский ввод будет состоять только
из символов простраства BMP (Basic Multilingual Plane). Но, в связи с особенностями представления unicode в java (
используются суррогатные пары char'ов для supplementary plane) пользователь может упереться в лимит раньше.
Например, если пользователь пришлет текст, состоящий только из символов дополнительных плоскостей (U+10000 - U+10FFFF),
то он получит ошибку валидации раньше.

Т.к. больших объемов текста со стороны пользователя не предполагается - нет необходимости добавлять в api возможность
загрузки бинарных данных. Как и не было смысла в применении оптимизированных коллекций (работающих с примитивными типами
данных).

Для текста выполняется нормализация до канонически эквивалентной формы (NFC).
Это приводит к соответствующим изменениям в подсчете вхождений: канонически эквивалентные символы, но закодированные
разными способами считаются одним и тем же символом.
